# 打分机制

## TF 
词频（TF，Term Frequency）: 词频表示一个词在文档中出现的频率。假设我们想计算一个词在文档中是否重要，通常来说，出现频率较高的词往往在该文档中更为重要。词频的计算公式为：

$\text{TF}(t, d) = \frac{\text{词 } t \text{ 在文档 } d \text{ 中出现的次数}}{\text{文档 } d \text{ 中所有词的总数}}$
其中:

- t 是目标词
- d 是目标文档
- 分母是文档中所有词的总数，用来归一化词频，以防文档长度过长时产生偏差。
## IDF
逆文档频率（IDF，Inverse Document Frequency）： 逆文档频率衡量的是某个词在整个文档集中的稀有程度。如果一个词在很多文档中都出现，那么这个词对区分文档的重要性就较低；反之，出现在少数文档中的词更有可能是区分不同文档的关键词。逆文档频率的计算公式为：

$\text{IDF}(t, D) = \log\left(\frac{|D|}{|\{d \in D : t \in d\}|}\right)$

其中:

- ∣D∣ 是整个文档集中的文档总数。
- ∣{d∈D:t∈d}∣ 是包含词 
- t 的文档数量。
对数运算可以平衡频繁出现的词对结果的影响，避免其分数过大。

## TF-IDF
$\text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D)$
这个值反映了词 t 在文档 d 中的相对重要性，且可以用于文档的排序、关键词提取等任务。